#include <ros/ros.h>
#include <sensor_msgs/Image.h>
#include <sensor_msgs/PointCloud2.h>
#include <cv_bridge/cv_bridge.h>
#include <pcl_ros/point_cloud.h>
#include <pcl_conversions/pcl_conversions.h>
#include <image_transport/image_transport.h>
#include <pcl/point_types.h>
#include <pcl/range_image/range_image_spherical.h>
#include <pcl/filters/voxel_grid.h>
#include <pcl/filters/statistical_outlier_removal.h>
#include <pcl/filters/radius_outlier_removal.h>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/calib3d/calib3d.hpp>
#include <armadillo>
#include <message_filters/subscriber.h>
#include <message_filters/synchronizer.h>
#include <message_filters/sync_policies/approximate_time.h>
#include <message_filters/sync_policies/exact_time.h>
#include <Eigen/Dense>
#include <sstream>
#include <chrono>
#include <thread>
#include <stdexcept>

using namespace Eigen;
using namespace sensor_msgs;
using namespace message_filters;
using namespace std;
using namespace arma;

typedef pcl::PointCloud<pcl::PointXYZI> PointCloud;

// Global Publishers
ros::Publisher pcOnimg_pub;
ros::Publisher pc_pub;
ros::Publisher range_image_pub;

// Configuration Parameters
struct Config {
    float maxlen = 100.0f;
    float minlen = 0.01f;
    float max_FOV = 3.0f;
    float min_FOV = 0.4f;
    float angular_resolution_x = 0.5f;
    float angular_resolution_y = 2.1f;
    float max_angle_width = 360.0f;
    float max_angle_height = 180.0f;
    float max_depth = 100.0f;
    float min_depth = 8.0f;
    double max_var = 50.0;
    float interpol_value = 20.0f;
    float far_depth_threshold = 50.0f;
    float far_interpol_scale = 0.5f;
    float max_interpol_scale = 0.2f; // Maximum step size reduction
    float interpol_steepness = 0.1f; // Steepness of logistic function
    bool filter_pc = true;
    float voxel_leaf_size = 0.1f;
    int sor_mean_k = 50;
    float sor_stddev = 1.0f;
    float radius_search = 0.5f;
    int min_neighbors = 5;
    bool use_exact_sync = false;
    bool use_intensity_color = false;
    std::string imgTopic = "/camera/color/image_raw";
    std::string pcTopic = "/velodyne_points";
};

// Calibration Matrices
Eigen::MatrixXf Tlc(3, 1);
Eigen::MatrixXf Rlc(3, 3);
Eigen::MatrixXf Mc(3, 3);
Eigen::MatrixXf Dc(1, 5);

// Range Image
boost::shared_ptr<pcl::RangeImageSpherical> rangeImage;
pcl::RangeImage::CoordinateFrame coordinate_frame = pcl::RangeImage::LASER_FRAME;

// Function to convert Eigen matrix to string
template<typename Derived>
std::string eigenToString(const Eigen::MatrixBase<Derived>& mat) {
    std::stringstream ss;
    ss << mat.format(IOFormat(4, 0, ", ", "\n", "[", "]"));
    return ss.str();
}

// Function to validate rotation matrix
bool isValidRotationMatrix(const Eigen::Matrix3f& R) {
    Eigen::Matrix3f shouldBeIdentity = R * R.transpose();
    Eigen::Matrix3f I = Eigen::Matrix3f::Identity();
    return (shouldBeIdentity - I).norm() < 1e-6;
}

// Function to load ROS parameters
void loadParameters(ros::NodeHandle& nh, Config& cfg) {
    nh.param("/maxlen", cfg.maxlen, cfg.maxlen);
    nh.param("/minlen", cfg.minlen, cfg.minlen);
    nh.param("/max_ang_FOV", cfg.max_FOV, cfg.max_FOV);
    nh.param("/min_ang_FOV", cfg.min_FOV, cfg.min_FOV);
    nh.param("/pcTopic", cfg.pcTopic, cfg.pcTopic);
    nh.param("/imgTopic", cfg.imgTopic, cfg.imgTopic);
    nh.param("/max_var", cfg.max_var, cfg.max_var);
    nh.param("/filter_output_pc", cfg.filter_pc, cfg.filter_pc);
    nh.param("/x_resolution", cfg.angular_resolution_x, cfg.angular_resolution_x);
    nh.param("/y_interpolation", cfg.interpol_value, cfg.interpol_value);
    nh.param("/ang_Y_resolution", cfg.angular_resolution_y, cfg.angular_resolution_y);
    nh.param("/voxel_leaf_size", cfg.voxel_leaf_size, cfg.voxel_leaf_size);
    nh.param("/sor_mean_k", cfg.sor_mean_k, cfg.sor_mean_k);
    nh.param("/sor_stddev", cfg.sor_stddev, cfg.sor_stddev);
    nh.param("/radius_search", cfg.radius_search, cfg.radius_search);
    nh.param("/min_neighbors", cfg.min_neighbors, cfg.min_neighbors);
    nh.param("/use_exact_sync", cfg.use_exact_sync, cfg.use_exact_sync);
    nh.param("/use_intensity_color", cfg.use_intensity_color, cfg.use_intensity_color);
    nh.param("/far_depth_threshold", cfg.far_depth_threshold, cfg.far_depth_threshold);
    nh.param("/far_interpol_scale", cfg.far_interpol_scale, cfg.far_interpol_scale);
    nh.param("/max_interpol_scale", cfg.max_interpol_scale, cfg.max_interpol_scale);
    nh.param("/interpol_steepness", cfg.interpol_steepness, cfg.interpol_steepness);

    XmlRpc::XmlRpcValue param;
    if (nh.getParam("/matrix_file/tlc", param) && param.size() == 3) {
        Tlc << static_cast<double>(param[0]), static_cast<double>(param[1]), static_cast<double>(param[2]);
        ROS_INFO("Loaded Tlc: \n%s", eigenToString(Tlc).c_str());
    } else {
        ROS_WARN("Invalid Tlc, using default");
        Tlc << 0.0, 0.0, 0.0;
    }

    if (nh.getParam("/matrix_file/rlc", param) && param.size() == 9) {
        Rlc << static_cast<double>(param[0]), static_cast<double>(param[1]), static_cast<double>(param[2]),
               static_cast<double>(param[3]), static_cast<double>(param[4]), static_cast<double>(param[5]),
               static_cast<double>(param[6]), static_cast<double>(param[7]), static_cast<double>(param[8]);
        if (!isValidRotationMatrix(Rlc)) {
            ROS_WARN("Rlc is not a valid rotation matrix, using identity");
            Rlc.setIdentity();
        }
        ROS_INFO("Loaded Rlc: \n%s", eigenToString(Rlc).c_str());
    } else {
        ROS_WARN("Invalid Rlc, using identity");
        Rlc.setIdentity();
    }

    if (nh.getParam("/matrix_file/camera_matrix", param) && param.size() == 9) {
        Mc << static_cast<double>(param[0]), static_cast<double>(param[1]), static_cast<double>(param[2]),
              static_cast<double>(param[3]), static_cast<double>(param[4]), static_cast<double>(param[5]),
              static_cast<double>(param[6]), static_cast<double>(param[7]), static_cast<double>(param[8]);
        ROS_INFO("Loaded Mc: \n%s", eigenToString(Mc).c_str());
    } else {
        ROS_WARN("Invalid camera matrix, using default");
        Mc << 1000.0, 0.0, 640.0,
              0.0, 1000.0, 360.0,
              0.0, 0.0, 1.0;
    }

    if (nh.getParam("/matrix_file/distortion_coeffs", param) && param.size() == 5) {
        Dc << static_cast<double>(param[0]), static_cast<double>(param[1]), static_cast<double>(param[2]),
              static_cast<double>(param[3]), static_cast<double>(param[4]);
        ROS_INFO("Loaded Dc: \n%s", eigenToString(Dc).c_str());
    } else {
        ROS_WARN("Invalid distortion coefficients, using zeros");
        Dc.setZero();
    }
}

// Function to filter point cloud
void filterPointCloud(const PointCloud::Ptr& cloud_in, PointCloud::Ptr& cloud_out, const Config& cfg) {
    // Remove NaN points
    std::vector<int> indices;
    pcl::removeNaNFromPointCloud(*cloud_in, *cloud_out, indices);
    ROS_DEBUG("Removed NaN points, remaining: %zu", cloud_out->points.size());

    // Distance-based filtering
    PointCloud::Ptr temp_cloud(new PointCloud);
    for (const auto& point : cloud_out->points) {
        double distance = std::sqrt(point.x * point.x + point.y * point.y);
        if (distance >= cfg.minlen && distance <= cfg.maxlen) {
            temp_cloud->push_back(point);
        }
    }
    cloud_out->swap(*temp_cloud);
    ROS_DEBUG("After distance filter, points: %zu", cloud_out->points.size());

    // Voxel Grid Downsampling
    pcl::VoxelGrid<pcl::PointXYZI> voxel;
    voxel.setInputCloud(cloud_out);
    voxel.setLeafSize(cfg.voxel_leaf_size, cfg.voxel_leaf_size, cfg.voxel_leaf_size);
    voxel.filter(*temp_cloud);
    cloud_out->swap(*temp_cloud);
    ROS_DEBUG("After voxel filter, points: %zu", cloud_out->points.size());

    // Statistical Outlier Removal
    pcl::StatisticalOutlierRemoval<pcl::PointXYZI> sor;
    sor.setInputCloud(cloud_out);
    sor.setMeanK(cfg.sor_mean_k);
    sor.setStddevMulThresh(cfg.sor_stddev);
    sor.filter(*temp_cloud);
    cloud_out->swap(*temp_cloud);
    ROS_DEBUG("After SOR filter, points: %zu", cloud_out->points.size());

    // Radius Outlier Removal
    pcl::RadiusOutlierRemoval<pcl::PointXYZI> ror;
    ror.setInputCloud(cloud_out);
    ror.setRadiusSearch(cfg.radius_search);
    ror.setMinNeighborsInRadius(cfg.min_neighbors);
    ror.filter(*temp_cloud);
    cloud_out->swap(*temp_cloud);
    ROS_DEBUG("After ROR filter, points: %zu", cloud_out->points.size());
}

// Function to create range image
void createRangeImage(const PointCloud::Ptr& cloud, const Config& cfg) {
    Eigen::Affine3f sensorPose = Eigen::Affine3f::Identity();
    rangeImage->createFromPointCloud(
        *cloud,
        pcl::deg2rad(cfg.angular_resolution_x),
        pcl::deg2rad(cfg.angular_resolution_y),
        pcl::deg2rad(cfg.max_angle_width),
        pcl::deg2rad(cfg.max_angle_height),
        sensorPose,
        coordinate_frame,
        0.0f,
        0.0f,
        0
    );
    ROS_DEBUG("Created range image: %u x %u", rangeImage->width, rangeImage->height);
}

// Function to interpolate depth image with enhanced far-region density
void interpolateDepthImage(const Config& cfg, arma::mat& ZI, arma::mat& ZzI) {
    arma::mat Z(rangeImage->height, rangeImage->width, fill::zeros);
    arma::mat Zz(rangeImage->height, rangeImage->width, fill::zeros);

    // Populate depth and height matrices
    for (unsigned int i = 0; i < rangeImage->width; ++i) {
        for (unsigned int j = 0; j < rangeImage->height; ++j) {
            float r = rangeImage->getPoint(i, j).range;
            float zz = rangeImage->getPoint(i, j).z;
            if (std::isinf(r) || std::isnan(zz) || r < cfg.minlen || r > cfg.maxlen) {
                continue;
            }
            Z(j, i) = r;
            Zz(j, i) = zz;
        }
    }

    // Adaptive interpolation with non-linear step size
    arma::vec X = arma::regspace(1, Z.n_cols);
    arma::vec Y = arma::regspace(1, Z.n_rows);

    // Compute depth-dependent step size using logistic function
    auto compute_step_size = [&](double depth) {
        if (depth <= cfg.far_depth_threshold) {
            return 1.0 / cfg.interpol_value;
        }
        double t = (depth - cfg.far_depth_threshold) * cfg.interpol_steepness;
        double scale = cfg.far_interpol_scale + (cfg.max_interpol_scale - cfg.far_interpol_scale) /
                       (1.0 + std::exp(-t));
        return 1.0 / cfg.interpol_value * scale;
    };

    // Estimate maximum output size
    double min_step = compute_step_size(cfg.maxlen);
    arma::vec XI = arma::regspace(X.min(), 1.0, X.max());
    arma::vec YI = arma::regspace(Y.min(), min_step, Y.max());

    arma::mat Z_temp, Zz_temp;
    arma::interp2(X, Y, Z, XI, YI, Z_temp, "linear");
    arma::interp2(X, Y, Zz, XI, YI, Zz_temp, "linear");

    // Initialize output matrices
    ZI.zeros(YI.n_elem, XI.n_elem);
    ZzI.zeros(YI.n_elem, XI.n_elem);

    // Copy initial interpolation
    for (uword i = 0; i < Z_temp.n_rows && i < ZI.n_rows; ++i) {
        for (uword j = 0; j < Z_temp.n_cols && j < ZI.n_cols; ++j) {
            ZI(i, j) = Z_temp(i, j);
            ZzI(i, j) = Zz_temp(i, j);
        }
    }

    // Depth-weighted Gaussian interpolation
    double sigma_spatial = 2.0;
    double sigma_depth = cfg.maxlen / 10.0;
    double density_threshold = 0.05;
    int max_window_size = 9;
    int min_window_size = 3;

    auto interpolate_region = [&](arma::mat& Z_out, const arma::mat& Z_in, uword start_row, uword end_row) {
        for (uword i = start_row; i < end_row && i < Z_out.n_rows - 1; ++i) {
            for (uword j = 1; j < Z_out.n_cols - 1; ++j) {
                if (Z_out(i, j) == 0 || Z_out(i, j) > cfg.far_depth_threshold) {
                    // Compute local density
                    int valid_neighbors = 0;
                    for (int di = -1; di <= 1; ++di) {
                        for (int dj = -1; dj <= 1; ++dj) {
                            uword ni = i + di;
                            uword nj = j + dj;
                            if (ni < Z_out.n_rows && nj < Z_out.n_cols && Z_out(ni, nj) > 0) {
                                valid_neighbors++;
                            }
                        }
                    }

                    // Adjust window size based on depth and density
                    int window_size = (Z_out(i, j) > cfg.far_depth_threshold || valid_neighbors < density_threshold * 9) ?
                                      max_window_size : min_window_size;
                    double weighted_sum = 0.0;
                    double weight_total = 0.0;

                    for (int di = -window_size; di <= window_size; ++di) {
                        for (int dj = -window_size; dj <= window_size; ++dj) {
                            uword ni = i + di;
                            uword nj = j + dj;
                            if (ni < Z_out.n_rows && nj < Z_out.n_cols && Z_out(ni, nj) > 0) {
                                double spatial_dist = std::sqrt(di * di + dj * dj);
                                double depth_dist = std::abs(Z_out(ni, nj) - Z_out(i, j));
                                // Increase weight for far points
                                double depth_weight = Z_out(ni, nj) > cfg.far_depth_threshold ? 1.5 : 1.0;
                                double weight = depth_weight * std::exp(-(spatial_dist * spatial_dist) / (2 * sigma_spatial * sigma_spatial) -
                                                                       (depth_dist * depth_dist) / (2 * sigma_depth * sigma_depth));
                                weighted_sum += Z_out(ni, nj) * weight;
                                weight_total += weight;
                            }
                        }
                    }

                    if (weight_total > 0) {
                        Z_out(i, j) = weighted_sum / weight_total;
                    }
                }
            }
        }
    };

    // Parallelize interpolation
    uint num_threads = std::thread::hardware_concurrency();
    std::vector<std::thread> threads;
    uword rows_per_thread = ZI.n_rows / num_threads;
    for (uint t = 0; t < num_threads; ++t) {
        uword start_row = t * rows_per_thread;
        uword end_row = (t == num_threads - 1) ? ZI.n_rows : start_row + rows_per_thread;
        threads.emplace_back(interpolate_region, std::ref(ZI), std::ref(Z_temp), start_row, end_row);
        threads.emplace_back(interpolate_region, std::ref(ZzI), std::ref(Zz_temp), start_row, end_row);
    }
    for (auto& thread : threads) {
        thread.join();
    }

    // Edge preservation using bilateral filter
    arma::mat grad_x = arma::zeros(ZI.n_rows, ZI.n_cols);
    arma::mat grad_y = arma::zeros(ZI.n_rows, ZI.n_cols);
    arma::mat grad_mag = arma::zeros(ZI.n_rows, ZI.n_cols);

    for (uword i = 1; i < ZI.n_rows - 1; ++i) {
        for (uword j = 1; j < ZI.n_cols - 1; ++j) {
            if (ZI(i, j) > 0) {
                grad_x(i, j) = (ZI(i, j + 1) - ZI(i, j - 1)) * 0.5;
                grad_y(i, j) = (ZI(i + 1, j) - ZI(i - 1, j)) * 0.5;
                grad_mag(i, j) = std::sqrt(grad_x(i, j) * grad_x(i, j) + grad_y(i, j) * grad_y(i, j));
            }
        }
    }

    double edge_threshold = 0.1 * arma::max(arma::max(grad_mag));
    arma::mat Zenhanced = ZI;
    for (uword i = 1; i < ZI.n_rows - 1; ++i) {
        for (uword j = 1; j < ZI.n_cols - 1; ++j) {
            if (grad_mag(i, j) > edge_threshold) {
                double weight = std::max(0.0, 1.0 - grad_mag(i, j) / edge_threshold);
                Zenhanced(i, j) = ZI(i, j) * weight + Zenhanced(i, j) * (1 - weight);
            }
        }
    }
    ZI = Zenhanced;

    if (cfg.filter_pc) {
        // Variance-based filtering
        arma::mat Zout = ZI;
        for (uword i = 0; i < (ZI.n_rows - 1) / cfg.interpol_value; ++i) {
            for (uword j = 0; j < ZI.n_cols - 5; ++j) {
                double promedio = 0;
                double varianza = 0;
                for (uword k = 0; k < cfg.interpol_value; ++k) {
                    promedio += ZI(i * cfg.interpol_value + k, j);
                }
                promedio /= cfg.interpol_value;

                for (uword l = 0; l < cfg.interpol_value; ++l) {
                    varianza += std::pow(ZI(i * cfg.interpol_value + l, j) - promedio, 2.0);
                }
                if (varianza > cfg.max_var) {
                    for (uword m = 0; m < cfg.interpol_value; ++m) {
                        Zout(i * cfg.interpol_value + m, j) = 0;
                    }
                }
            }
        }
        ZI = Zout;
    }

    // Publish range image for debugging
    cv::Mat range_img(ZI.n_rows, ZI.n_cols, CV_32F, ZI.memptr());
    cv::normalize(range_img, range_img, 0, 255, cv::NORM_MINMAX, CV_8U);
    sensor_msgs::ImagePtr range_msg = cv_bridge::CvImage(std_msgs::Header(), "mono8", range_img).toImageMsg();
    range_image_pub.publish(range_msg);
}

// Function to convert range image to point cloud
void rangeImageToPointCloud(const arma::mat& ZI, const arma::mat& ZzI, const Config& cfg, PointCloud::Ptr& point_cloud) {
    point_cloud->width = ZI.n_cols;
    point_cloud->height = ZI.n_rows;
    point_cloud->is_dense = false;
    point_cloud->points.resize(point_cloud->width * point_cloud->height);

    int num_pc = 0;
    Eigen::Matrix3f Lidar_matrix;
    float ang_x_lidar = 0.6 * M_PI / 180.0;
    Lidar_matrix << std::cos(ang_x_lidar), 0, std::sin(ang_x_lidar),
                    0, 1, 0,
                    -std::sin(ang_x_lidar), 0, std::cos(ang_x_lidar);

    for (uword i = 0; i < ZI.n_rows - cfg.interpol_value; ++i) {
        for (uword j = 0; j < ZI.n_cols; ++j) {
            float ang = M_PI - (2.0 * M_PI * j) / ZI.n_cols;
            if (ang < cfg.min_FOV - M_PI / 2.0 || ang > cfg.max_FOV - M_PI / 2.0) {
                continue;
            }
            if (ZI(i, j) == 0) {
                continue;
            }

            float pc_modulo = ZI(i, j);
            float pc_x = std::sqrt(pc_modulo * pc_modulo - ZzI(i, j) * ZzI(i, j)) * std::cos(ang);
            float pc_y = std::sqrt(pc_modulo * pc_modulo - ZzI(i, j) * ZzI(i, j)) * std::sin(ang);

            Eigen::Vector3f result(pc_x, pc_y, ZzI(i, j));
            result = Lidar_matrix * result;

            point_cloud->points[num_pc].x = result(0);
            point_cloud->points[num_pc].y = result(1);
            point_cloud->points[num_pc].z = result(2);
            point_cloud->points[num_pc].intensity = ZI(i, j);
            num_pc++;
        }
    }
    point_cloud->points.resize(num_pc);
    ROS_DEBUG("Converted to point cloud with %d points", num_pc);
}

// Function to project point cloud onto image with sub-pixel accuracy
void projectPointCloudToImage(
    const PointCloud::Ptr& point_cloud,
    const cv::Mat& image,
    const Config& cfg,
    pcl::PointCloud<pcl::PointXYZRGB>::Ptr& pc_color,
    cv_bridge::CvImagePtr& cv_ptr
) {
    Eigen::Matrix4f RTlc;
    RTlc << Rlc(0, 0), Rlc(0, 1), Rlc(0, 2), Tlc(0),
            Rlc(1, 0), Rlc(1, 1), Rlc(1, 2), Tlc(1),
            Rlc(2, 0), Rlc(2, 1), Rlc(2, 2), Tlc(2),
            0, 0, 0, 1;

    cv::Mat camera_matrix = (cv::Mat_<double>(3, 3) <<
        Mc(0, 0), Mc(0, 1), Mc(0, 2),
        Mc(1, 0), Mc(1, 1), Mc(1, 2),
        Mc(2, 0), Mc(2, 1), Mc(2, 2));
    cv::Mat dist_coeffs = (cv::Mat_<double>(1, 5) <<
        Dc(0), Dc(1), Dc(2), Dc(3), Dc(4));

    unsigned int cols = image.cols;
    unsigned int rows = image.rows;

    std::vector<cv::Point2f> points;
    std::vector<cv::Point3f> points_3d;
    for (const auto& point : point_cloud->points) {
        points_3d.emplace_back(-point.y, -point.z, point.x);
    }

    std::vector<cv::Point2f> points_2d;
    cv::projectPoints(points_3d, cv::Mat::eye(3, 3, CV_64F), cv::Mat::zeros(3, 1, CV_64F), camera_matrix, dist_coeffs, points_2d);

    for (size_t i = 0; i < point_cloud->points.size(); ++i) {
        float px = points_2d[i].x;
        float py = points_2d[i].y;
        unsigned int px_data = static_cast<unsigned int>(px);
        unsigned int py_data = static_cast<unsigned int>(py);

        if (px_data >= cols - 1 || py_data >= rows - 1) {
            continue;
        }

        // Bilinear interpolation for color
        float fx = px - px_data;
        float fy = py - py_data;
        cv::Vec3b c00 = image.at<cv::Vec3b>(py_data, px_data);
        cv::Vec3b c01 = image.at<cv::Vec3b>(py_data, px_data + 1);
        cv::Vec3b c10 = image.at<cv::Vec3b>(py_data + 1, px_data);
        cv::Vec3b c11 = image.at<cv::Vec3b>(py_data + 1, px_data + 1);

        cv::Vec3f color;
        for (int k = 0; k < 3; ++k) {
            color[k] = (1 - fx) * (1 - fy) * c00[k] +
                       fx * (1 - fy) * c01[k] +
                       (1 - fx) * fy * c10[k] +
                       fx * fy * c11[k];
        }

        pcl::PointXYZRGB point;
        point.x = point_cloud->points[i].x;
        point.y = point_cloud->points[i].y;
        point.z = point_cloud->points[i].z;
        point.r = static_cast<uint8_t>(color[2]);
        point.g = static_cast<uint8_t>(color[1]);
        point.b = static_cast<uint8_t>(color[0]);
        pc_color->points.push_back(point);

        int color_value = cfg.use_intensity_color ?
                          static_cast<int>(255 * (point_cloud->points[i].intensity / cfg.maxlen)) :
                          static_cast<int>(255 * (point_cloud->points[i].x / cfg.maxlen));
        int color_dis_z = static_cast<int>(255 * (point_cloud->points[i].x / 10.0));
        if (color_dis_z > 255) color_dis_z = 255;

        cv::circle(cv_ptr->image, cv::Point(px_data, py_data), 1, CV_RGB(255 - color_value, color_dis_z, color_value), cv::FILLED);
    }

    pc_color->is_dense = true;
    pc_color->width = pc_color->points.size();
    pc_color->height = 1;
    pc_color->header.frame_id = "velodyne";
}

// Callback function
void callback(const PointCloud2ConstPtr& in_pc2, const ImageConstPtr& in_image, const Config& cfg) {
    auto start = std::chrono::high_resolution_clock::now();

    // Validate timestamps
    if (std::abs((in_pc2->header.stamp - in_image->header.stamp).toSec()) > 0.1) {
        ROS_WARN("Timestamp mismatch between point cloud and image");
        return;
    }

    // Convert image to OpenCV format
    cv_bridge::CvImagePtr cv_ptr, color_pcl;
    try {
        cv_ptr = cv_bridge::toCvCopy(in_image, sensor_msgs::image_encodings::BGR8);
        color_pcl = cv_bridge::toCvCopy(in_image, sensor_msgs::image_encodings::BGR8);
    } catch (cv_bridge::Exception& e) {
        ROS_ERROR("cv_bridge exception: %s", e.what());
        return;
    }

    if (cv_ptr->image.empty()) {
        ROS_WARN("Empty image received");
        return;
    }

    // Convert PointCloud2 to PCL
    pcl::PCLPointCloud2 pcl_pc2;
    pcl_conversions::toPCL(*in_pc2, pcl_pc2);
    PointCloud::Ptr msg_pointCloud(new PointCloud);
    pcl::fromPCLPointCloud2(pcl_pc2, *msg_pointCloud);
    if (msg_pointCloud->empty()) {
        ROS_WARN("Empty point cloud received");
        return;
    }

    // Filter point cloud
    PointCloud::Ptr cloud_filtered(new PointCloud);
    filterPointCloud(msg_pointCloud, cloud_filtered, cfg);

    // Create range image
    createRangeImage(cloud_filtered, cfg);

    // Interpolate depth image
    arma::mat ZI, ZzI;
    interpolateDepthImage(cfg, ZI, ZzI);

    // Convert range image to point cloud
    PointCloud::Ptr point_cloud(new PointCloud);
    rangeImageToPointCloud(ZI, ZzI, cfg, point_cloud);

    // Project point cloud onto image
    pcl::PointCloud<pcl::PointXYZRGB>::Ptr pc_color(new pcl::PointCloud<pcl::PointXYZRGB>);
    projectPointCloudToImage(point_cloud, color_pcl->image, cfg, pc_color, cv_ptr);

    // Publish results
    pcOnimg_pub.publish(cv_ptr->toImageMsg());
    pc_pub.publish(pc_color);

    auto end = std::chrono::high_resolution_clock::now();
    ROS_DEBUG("Callback processing time: %ld ms", std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count());
}

int main(int argc, char** argv) {
    ros::init(argc, argv, "lidar_camera_fusion");
    ros::NodeHandle nh;

    Config cfg;
    try {
        loadParameters(nh, cfg);
    } catch (const std::exception& e) {
        ROS_ERROR("Initialization failed: %s", e.what());
        return 1;
    }

    rangeImage = boost::shared_ptr<pcl::RangeImageSpherical>(new pcl::RangeImageSpherical);
    pcOnimg_pub = nh.advertise<sensor_msgs::Image>("/pcOnImage_image", 1);
    pc_pub = nh.advertise<PointCloud>("/points2", 1);
    range_image_pub = nh.advertise<sensor_msgs::Image>("/range_image", 1);

    message_filters::Subscriber<PointCloud2> pc_sub(nh, cfg.pcTopic, 1);
    message_filters::Subscriber<Image> img_sub(nh, cfg.imgTopic, 1);

    if (cfg.use_exact_sync) {
        typedef sync_policies::ExactTime<PointCloud2, Image> MySyncPolicy;
        Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), pc_sub, img_sub);
        sync.registerCallback(boost::bind(&callback, _1, _2, cfg));
    } else {
        typedef sync_policies::ApproximateTime<PointCloud2, Image> MySyncPolicy;
        Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), pc_sub, img_sub);
        sync.registerCallback(boost::bind(&callback, _1, _2, cfg));
    }

    ROS_INFO("LiDAR-Camera fusion node started");
    ros::spin();
    return 0;
}
